{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","from matplotlib import pyplot as plt\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#   MERGE method\n","frame1 = pd.DataFrame()\n","frame2 = pd.DataFrame()\n","newMerged = frame1.merge(frame2, on=\"columnToUse\")\n","\n","# SUFFIXES\n","newMerged = frame1.merge(frame2, on=\"columnToUse\", suffixes='_from1','_from2')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Merge the licenses and biz_owners table on account\n","licenses_owners = licenses.merge(biz_owners, on='account')\n","\n","# Group the results by title then count the number of accounts\n","counted_df = licenses_owners.groupby('title').agg({'account':'count'})\n","\n","############ what does this .agg function DO with this..dictionary?? weird\n","#Looks like this dictionary is JUST doing ONE method on ONE column, \n","# meaning you can also do mult methods on mult diff columsn, cool!\n","\n","\n","# Sort the counted_df in desending order\n","sorted_df = counted_df.sort_values('account', ascending=False)\n","\n","# Use .head() method to print the first few rows of sorted_df\n","print(sorted_df.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Merge land_use and census and merge result with licenses including suffixes\n","land_cen_lic = land_use.merge(census, on='ward') \\\n","                    .merge(licenses, on='ward', suffixes=('_cen','_lic'))\n","\n","# Group by ward, pop_2010, and vacant, then count the # of accounts\n","pop_vac_lic = land_cen_lic.groupby(['ward','pop_2010','vacant'], \n","                                   as_index=False).agg({'account':'count'})\n","\n","# Sort pop_vac_lic and print the results\n","sorted_pop_vac_lic = pop_vac_lic.sort_values(['vacant','account','pop_2010'], \\\n","                                             ascending=[False,True,False])\n","\n","# Print the top few rows of sorted_pop_vac_lic\n","print(sorted_pop_vac_lic.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# LEFT JOIN M PANDAS\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# OUTER JOIN to find UNIQUE ROWS that are in EITHER but not BOTH\n","\n","# Merge iron_1_actors to iron_2_actors on id with outer join using suffixes\n","iron_1_and_2 = iron_1_actors.merge(iron_2_actors, on='id', how='outer', suffixes=['_1','_2'])\n","\n","# Create an index that returns true if name_1 or name_2 are null\n","m = ( (iron_1_and_2['name_1'].isnull()) | (iron_1_and_2['name_2'].isnull()) )\n","\n","# Print the first few rows of iron_1_and_2\n","print(iron_1_and_2[m].head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# SELF JOIN\n","# Merge the crews table to itself\n","crews_self_merged = crews.merge(crews, on='id', how='inner',\n","                                suffixes=('_dir','_crew'))\n","\n","# Create a boolean index to select the appropriate rows\n","boolean_filter = ((crews_self_merged['job_dir'] == 'Director') & \n","                  (crews_self_merged['job_crew'] != 'Director'))\n","direct_crews = crews_self_merged[boolean_filter]\n","\n","# Print the first few rows of direct_crews\n","print(direct_crews.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#  MERGE ON  INDEXES\n","# IF merge using LEFT ON or RIGHT ON, and one of those is an INDEX, \n","# make sure to use - \n","\n","left_index = True \n","x = y.merge(ztable, on='id', left_index=True)\n","\n","#  MERGE ON MULTI INDEX\n","Sam_casts = sam.merge(casts, on=['movie_id','cast_id'])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# EXERCISE  merge tables on their index,\n","#  merge another table to itself\n","# after the calculations were added and sub-select specific columns,\n","# sorted data to find which movie sequels had high improvement in revenue compared to the original\n","\n","# Merge sequels and financials on index id\n","sequels_fin = sequels.merge(financials, on='id', how='left')\n","\n","# Self merge with suffixes as inner join with left on sequel and right on id\n","orig_seq = sequels_fin.merge(sequels_fin, how='inner', left_on='sequel', \n","                             right_on='id', right_index=True,\n","                             suffixes=('_org','_seq'))\n","\n","# Add calculation to subtract revenue_org from revenue_seq \n","orig_seq['diff'] = orig_seq['revenue_seq'] - orig_seq['revenue_org']\n","\n","# Select the title_org, title_seq, and diff \n","titles_diff = orig_seq[['title_org','title_seq','diff']]\n","\n","# Print the first rows of the sorted titles_diff\n","print(titles_diff.sort_values('diff', ascending=False).head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#SEMI JOIN - using genres and tracks\n","#FILTERING JOIN\n","# which genres are represented in a list of top songs?\n","# 1, merge genres and top tracks on their id\n","genres_tracks = genres.merge(top_tracks, on='gid')\n","\n","# 2, select rows from merged table that WERE in Left table. No rows from R table get selected!\n","genres['gid'].isin( genres_tracks['gid'] )\n","\n","# return here is a Boole4an Series, & sub that in like before\n","# to subset the Genres table\n","top_genres = genres[ genres['gid'].isin( genres_tracks['gid'] ) ]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#ANTI JOIN\n","\n","# 1, merge genres and top tracks on their id\n","#indicator adds a col to output, \"_merge\", showing: BOTH, LEFT_ONLY, RIGHT_ONLY\n","genres_tracks = genres.merge(top_tracks, on='gid', how='left', indicator=True)\n","\n","# now get list of gids that are in Left table only, i.e. NOT in top tracks\n","notInTopList = genres_tracks.loc[genres_tracks['_merge'] == 'left_only', 'gid']\n","\n","#finally filter the total gid list to see which GENRES had no representn in TOP TRACKS \n","\n","notTopGenres = genres[genres['gid'].isin(notInTopList)]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#EXERCISES - ANTIJOIN\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# EXERCISE - SEMI JOIN\n","\n","# Merge the non_mus_tck and top_invoices tables on tid\n","tracks_invoices = non_mus_tcks.merge(top_invoices, on='tid')\n","\n","# Use .isin() to subset non_mus_tcks to rows with tid in tracks_invoices\n","top_tracks = non_mus_tcks[non_mus_tcks['tid'].isin(tracks_invoices['tid'])]\n","\n","# Group the top_tracks by gid and count the tid rows\n","cnt_by_gid = top_tracks.groupby(['gid'], as_index=False).agg({'tid':'count'})\n","\n","# Merge the genres table to cnt_by_gid on gid and print\n","print(cnt_by_gid.merge(genres, on='gid'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#CONCATTING TABLES\n","\n","# Concatenate the tables and add keys\n","inv_jul_thr_sep = pd.concat([inv_jul, inv_aug, inv_sep], \n","                            keys=['7Jul', '8Aug','9Sep'])\n","\n","# Group the invoices by the index keys and find avg of the total column\n","avg_inv_by_month = inv_jul_thr_sep.groupby(level=0).agg({'total':'mean'})\n","\n","# Bar plot of avg_inv_by_month\n","import matplotlib.pyplot as plt\n","\n","avg_inv_by_month.plt(kind='bar')\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# EXERCISES semo join, concat...\n","\n","# Concatenate the classic tables vertically\n","classic_18_19 = pd.concat([classic_18, classic_19], ignore_index=True)\n","\n","# Concatenate the pop tables vertically\n","pop_18_19 = pd.concat([pop_18, pop_19], ignore_index=True)\n","\n","# Merge classic_18_19 with pop_18_19\n","classic_pop = classic_18_19.merge(pop_18_19, on='tid')\n","\n","# Using .isin(), filter classic_18_19 rows where tid is in classic_pop\n","popular_classic = classic_18_19[classic_18_19['tid'].isin(classic_pop['tid'])]\n","\n","# Print popular chart\n","print(popular_classic)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# MERGE_ORDERED\n","# merge asof\n","\n","# Use merge_asof() to merge jpm and wells\n","jpm_wells = pd.merge_asof(jpm, wells, on='date_time', \n","                          suffixes=('', '_wells'), direction='nearest')\n","\n","# Use merge_asof() to merge jpm_wells and bac\n","jpm_wells_bac = pd.merge_asof(jpm_wells, bac, on='date_time', \n","                              suffixes=('_jpm', '_bac'), direction='nearest')\n","\n","# Compute price diff\n","price_diffs = jpm_wells_bac.diff()\n","\n","# Plot the price diff of the close of jpm, wells and bac only\n","price_diffs.plot(y=['close_jpm','close_wells','close_bac'])\n","plt.show()\n","\n","ok idk what went wrong \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Unpivot everything besides the year column\n","ur_tall = ur_wide.melt(id_vars=['year'], var_name='month', \n","                       value_name='unempl_rate')\n","\n","# Create a date column using the month and year columns of ur_tall\n","ur_tall['date'] = pd.to_datetime(ur_tall['month'] + '-' + ur_tall['year'])\n","\n","# Sort ur_tall by date in ascending order\n","ur_sorted = ur_tall.sort_values('date')\n","\n","# Plot the unempl_rate by date\n","ur_sorted.plot(x='date', y='unempl_rate')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use melt on ten_yr, unpivot everything besides the metric column\n","bond_perc = ten_yr.melt(id_vars='metric', var_name='date', value_name='close')\n","\n","# Use query on bond_perc to select only the rows where metric=close\n","bond_perc_close = bond_perc.query('metric == \"close\"')\n","\n","# Merge (ordered) dji and bond_perc_close on date with an inner join\n","dow_bond = pd.merge_ordered(dji, bond_perc_close, on='date', \n","                            suffixes=('_dow', '_bond'), how='inner')\n","\n","# Plot only the close_dow and close_bond columns\n","dow_bond.plot(y=['close_dow', 'close_bond'], x='date', rot=90)\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"8e3df8c37403ba4b3c8bfde5a26f1f7f6e1b2866f6dc0cdafb75725c9232505a"}}},"nbformat":4,"nbformat_minor":2}
